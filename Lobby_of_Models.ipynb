{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovVPvLSQwd4K"
   },
   "source": [
    "## Import the Necessary functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wbal_J-lv-jr"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pprint\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, BatchNormalization\n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.signal import correlate, correlation_lags\n",
    "from datetime import datetime\n",
    "import random\n",
    "from math import inf\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PftYx7i7mLVk"
   },
   "source": [
    "# Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "sWVUKDhVmOto"
   },
   "outputs": [],
   "source": [
    "SUBSTITUE_VALUE = 1\n",
    "MAX_CONNECTORS = 10\n",
    "TIMESTEPS = 144\n",
    "\n",
    "weather_cols = ['G_0']    #[ 'G_0', 'RH', 'T_a']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ruggjk3wkry"
   },
   "source": [
    "# ML model class definition\n",
    "let's define the class for our ML Molel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BGIPV6uNwkEB"
   },
   "outputs": [],
   "source": [
    "class timeseries_ml_model:\n",
    "  def __init__(self,\n",
    "               time_steps,\n",
    "               input_features=48,\n",
    "               epochs=100,\n",
    "               batch_size=16,\n",
    "               save_best_model_during_training=False,\n",
    "               loss = 'binary_crossentropy',\n",
    "               metric = 'accuracy',\n",
    "               optimizer = 'adam',\n",
    "               last_activation = 'softmax',\n",
    "               output_size=3,\n",
    "               dense_neurons = 16\n",
    "               ):\n",
    "    self.time_steps = time_steps\n",
    "    self.input_features = input_features\n",
    "    self.epochs = epochs\n",
    "    self.batch_size = batch_size\n",
    "    self.optimizer = optimizer\n",
    "    self.last_activation = last_activation\n",
    "    self.x_train = None\n",
    "    self.x_test = None\n",
    "    self.y_train = None\n",
    "    self.y_test = None\n",
    "    self.model = None\n",
    "    self.dl_model = None\n",
    "    self.model_checkpoints = save_best_model_during_training\n",
    "    self.loss = loss\n",
    "    self.metric = metric\n",
    "    self.output_size = output_size\n",
    "    self.dense_neurons = dense_neurons\n",
    "\n",
    "  def create_model(self):\n",
    "    self.model = Sequential()\n",
    "    num_of_neurons = self.time_steps * self.input_features\n",
    "    self.model.add(LSTM(num_of_neurons, input_shape=(self.time_steps, self.input_features)))\n",
    "    self.model.add(Dense(self.dense_neurons, activation='relu'))\n",
    "    self.model.add(Dense(self.output_size, activation=self.last_activation))\n",
    "    self.model.compile(optimizer=self.optimizer, loss=self.loss, metrics=[self.metric])\n",
    "\n",
    "  def train_model(self):\n",
    "    if self.model_checkpoints:\n",
    "      filepath = 'callback_model.keras'\n",
    "      model_checkpoint_callback = ModelCheckpoint(filepath,\n",
    "                                                  monitor='val_loss',\n",
    "                                                  verbose=0,\n",
    "                                                  save_best_only=True,\n",
    "                                                  save_weights_only=False,\n",
    "                                                  mode='min',\n",
    "                                                  save_freq='epoch',\n",
    "                                                  initial_value_threshold=None\n",
    "                                                  )\n",
    "      self.model.fit(self.x_train,\n",
    "                     self.y_train,\n",
    "                     epochs=self.epochs,\n",
    "                     batch_size=self.batch_size,\n",
    "                     callbacks=[model_checkpoint_callback])\n",
    "    else:\n",
    "      self.model.fit(self.x_train,\n",
    "                     self.y_train,\n",
    "                     epochs=self.epochs,\n",
    "                     batch_size=self.batch_size,\n",
    "                     )\n",
    "\n",
    "  def get_data(self,\n",
    "               data,\n",
    "               target,\n",
    "               test_split,\n",
    "               random_state=42):\n",
    "    (self.x_train,\n",
    "     self.x_test,\n",
    "     self.y_train,\n",
    "     self.y_test) = train_test_split(data,\n",
    "                                     target,\n",
    "                                     test_size=test_split,\n",
    "                                     random_state=random_state)\n",
    "\n",
    "  def make_predictions(self, model=\"dl\"):\n",
    "    if model==\"dl\":\n",
    "      return self.dl_model.predict(self.x_test), self.y_test\n",
    "    else:\n",
    "      return self.model.predict(self.x_test), self.y_test\n",
    "\n",
    "  def make_dl_model(self):\n",
    "    self.dl_model = tf.keras.Sequential([\n",
    "          tf.keras.layers.Normalization(),\n",
    "\n",
    "          tf.keras.layers.Conv1D(128, 3, activation=\"relu\"),\n",
    "          tf.keras.layers.MaxPooling1D(),\n",
    "          tf.keras.layers.BatchNormalization(),\n",
    "          tf.keras.layers.Conv1D(256, 3, activation=\"relu\"),\n",
    "          tf.keras.layers.MaxPooling1D(),\n",
    "          tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "          tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
    "          tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
    "\n",
    "          tf.keras.layers.GlobalAveragePooling1D(),\n",
    "          tf.keras.layers.Dropout(0.5),\n",
    "\n",
    "          tf.keras.layers.Dense(3, activation=self.last_activation)\n",
    "    ])\n",
    "    self.dl_model.build(input_shape=(None,self.time_steps,self.input_features))\n",
    "    self.dl_model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "  def  train_dl_model(self):\n",
    "    self.dl_model.fit(self.x_train,\n",
    "                     self.y_train,\n",
    "                     epochs=self.epochs\n",
    "                     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4zRDerSUW7A"
   },
   "source": [
    "# Define the helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "aR4VVIRVUVqt"
   },
   "outputs": [],
   "source": [
    "\n",
    "def calucluate_mean_absolute_error(predictions, actuals):\n",
    "  # take the absolute difference between the predictions and the labels\n",
    "  absolute_errors = np.abs(predictions - actuals)\n",
    "  # calculate the mean absolute error\n",
    "  mean_absolute_error = np.mean(absolute_errors, axis=0)\n",
    "  return mean_absolute_error\n",
    "\n",
    "\n",
    "def get_sensor_data(path, index_column='datetime'):\n",
    "  data = pd.read_csv(path, index_col=index_column, parse_dates=True)\n",
    "  date_time = pd.to_datetime(data.index, format='%d.%m.%Y %H:%M:%S')\n",
    "  day = 24*60*60\n",
    "  year = (365.2425)*day\n",
    "  timestamp_s = date_time.map(pd.Timestamp.timestamp)\n",
    "  data['Day sin'] = np.sin(timestamp_s * (2 * np.pi / day))\n",
    "  return data\n",
    "\n",
    "\n",
    "\n",
    "def fix_lag(all_data, feature1, feature2, lag=None):\n",
    "  x = all_data[feature1]\n",
    "  y = all_data[feature2]\n",
    "\n",
    "  if lag is None:\n",
    "    correlation = correlate(all_data[feature1], all_data[feature2], mode=\"full\")\n",
    "    lags = correlation_lags(all_data[feature1].size, all_data[feature2].size, mode=\"full\")\n",
    "    lag = lags[np.argmax(correlation)]\n",
    "\n",
    "  if lag < 0:\n",
    "      x = x.iloc[:lag].reset_index(drop=True)\n",
    "      x = [np.nan] * abs(lag) + list(x)\n",
    "  else:\n",
    "      x = x.iloc[lag:].reset_index(drop=True)\n",
    "      x = list(x) + [np.nan] * lag\n",
    "  all_data.loc[:,feature1] = x\n",
    "  all_data.loc[:,feature2] = y\n",
    "\n",
    "  return all_data\n",
    "\n",
    "\n",
    "\n",
    "def get_string_exoskeletons(metadata_path):\n",
    "  string_1_exoskeltons = []\n",
    "  string_2_exoskeltons = []\n",
    "\n",
    "  try:\n",
    "      with open(metadata_path, 'r') as file:\n",
    "          metadata = json.load(file)\n",
    "      print(\"Metadata file read successfully!\")\n",
    "\n",
    "  except json.JSONDecodeError as err:\n",
    "      print(f\"JSON decode error: {err}\")\n",
    "      print(f\"Error at line {err.lineno}, column {err.colno}\")\n",
    "  except Exception as e:\n",
    "      print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "  sensor_class = {}\n",
    "  for sensor, meta in metadata['Sensor_metadata'].items():\n",
    "    if meta['String_id'] == 'String_1' and meta['sensor_type']=='V_T':\n",
    "      string_1_exoskeltons.append(sensor)\n",
    "    elif meta['String_id'] == 'String_2' and meta['sensor_type']=='V_T':\n",
    "      string_2_exoskeltons.append(sensor)\n",
    "    elif meta['sensor_type'] == 'I' and meta['String_id'] == 'String_1' and meta['Module_id'] == 'Inverter':\n",
    "      string_1_inv_sensor = sensor\n",
    "    elif meta['sensor_type'] == 'I' and meta['String_id'] == 'String_2' and meta['Module_id'] == 'Inverter':\n",
    "      string_2_inv_sensor = sensor\n",
    "    elif meta['sensor_type'] == 'I' and meta['String_id'] == 'String_1' and meta['Module_id'] != 'Inverter':\n",
    "      string_1_current_sensor = sensor\n",
    "    elif meta['sensor_type'] == 'I' and meta['String_id'] == 'String_2' and meta['Module_id'] != 'Inverter':\n",
    "      string_2_current_sensor = sensor\n",
    "\n",
    "    if meta['sensor_type'] == 'V_T':\n",
    "      sensor_class[sensor] = metadata['MC4_metadata'][meta['MC4_sample_id']]['label']\n",
    "\n",
    "  return (string_1_exoskeltons,\n",
    "          string_2_exoskeltons,\n",
    "          string_1_inv_sensor,\n",
    "          string_2_inv_sensor,\n",
    "          string_1_current_sensor,\n",
    "          string_2_current_sensor,\n",
    "          metadata)\n",
    "\n",
    "\n",
    "def append_shifted_inverter_data(input_data,\n",
    "                                 inverter_data_path,\n",
    "                                 index_column='datetime',\n",
    "                                 cols_of_interest=['U_dc_string1',\n",
    "                                                   'U_dc_string2',\n",
    "                                                   'I_dc_string1',\n",
    "                                                   'I_dc_string2']):\n",
    "  if inverter_data_path != '':\n",
    "    inv_data = pd.read_csv(inverter_data_path, index_col=index_column, parse_dates=True)\n",
    "    inv_data = inv_data[cols_of_interest]\n",
    "    inv_data.index = pd.to_datetime(inv_data.index)\n",
    "    input_data = pd.merge(input_data, inv_data, on=\"datetime\", how=\"inner\")\n",
    "\n",
    "  input_data.index = pd.to_datetime(input_data.index)\n",
    "\n",
    "  d2 = input_data[(input_data.index<='2024-03-29 23:59:59')]\n",
    "  d3 = input_data[input_data.index>'2024-03-29 23:59:59']\n",
    "\n",
    "  d2 = fix_lag(d2, 'I_dc_string1', 'I_FEFFFFB71E5E54E1', 13)\n",
    "  d3 = fix_lag(d3, 'I_dc_string1', 'I_FEFFFFB71E5E54E1', 1)\n",
    "\n",
    "  d2 = fix_lag(d2, 'I_dc_string2', 'I_FEFFFFB71E5E54E4', 13)\n",
    "  d3 = fix_lag(d3, 'I_dc_string2', 'I_FEFFFFB71E5E54E4', 1)\n",
    "\n",
    "  d2 = fix_lag(d2, 'U_dc_string1', 'I_FEFFFFB71E5E54E1', 13)\n",
    "  d3 = fix_lag(d3, 'U_dc_string1', 'I_FEFFFFB71E5E54E1', 1)\n",
    "\n",
    "  d2 = fix_lag(d2, 'U_dc_string2', 'I_FEFFFFB71E5E54E4', 13)\n",
    "  d3 = fix_lag(d3, 'U_dc_string2', 'I_FEFFFFB71E5E54E4', 1)\n",
    "\n",
    "  return pd.concat([d2,d3], axis=0)\n",
    "\n",
    "\n",
    "def derive_power_resistance_features( input_data,\n",
    "                                      _s1_exoskeletons,\n",
    "                                      _s2_exoskeletons,\n",
    "                                      _s1_current_sensor,\n",
    "                                      _s2_current_sensor\n",
    "                                      ):\n",
    "  input_data = input_data[(input_data[\"I_dc_string1\"]>0) | (input_data['I_dc_string2']>0)].copy()\n",
    "  #input_data[\"V_\"+string_1_current_sensor] = input_data[[\"V_\"+x for x in string_1_exoskeltons]].sum(axis=1)\n",
    "  input_data[\"P_string1\"] = input_data[\"I_dc_string1\"] * input_data[\"U_dc_string1\"]\n",
    "  input_data[\"R_string1\"] = input_data[\"U_dc_string1\"] / input_data[\"I_dc_string1\"]\n",
    "\n",
    "  #input_data[\"V_\"+string_2_current_sensor] = input_data[[\"V_\"+x for x in string_2_exoskeltons]].sum(axis=1)\n",
    "  input_data[\"P_string2\"] = input_data[\"I_dc_string2\"] * input_data[\"U_dc_string2\"]\n",
    "  input_data[\"R_string2\"] = input_data[\"U_dc_string2\"] / input_data[\"I_dc_string2\"]\n",
    "\n",
    "  for col in _s1_exoskeletons:\n",
    "    input_data[\"P_\"+col] = input_data[\"I_\"+_s1_current_sensor] * input_data[\"V_\"+col]\n",
    "    input_data[\"R_\"+col] = input_data[\"V_\"+col] / input_data[\"I_\"+_s1_current_sensor]\n",
    "\n",
    "  for col in _s2_exoskeletons:\n",
    "    input_data[\"P_\"+col] = input_data[\"I_\"+_s2_current_sensor] * input_data[\"V_\"+col]\n",
    "    input_data[\"R_\"+col] = input_data[\"V_\"+col] / input_data[\"I_\"+_s2_current_sensor]\n",
    "\n",
    "  return input_data\n",
    "\n",
    "def find_missing_days(df):\n",
    "    missingData = {}\n",
    "    years = set(df.index.year)\n",
    "    months = set(df.index.month)\n",
    "    for year in years:\n",
    "      missingData[year] = {}\n",
    "      for month in months:\n",
    "          absent_days=[]\n",
    "          try:\n",
    "            for day in range(min(set(df[(df.index.month==month) & (df.index.year==year)].index.day)),\n",
    "                            max(set(df[(df.index.month==month) & (df.index.year==year)].index.day))+1):\n",
    "                if day not in set(df[df.index.month==month].index.day):\n",
    "                    absent_days.append(day)\n",
    "          except:\n",
    "            pass\n",
    "      missingData[year][month] = absent_days\n",
    "    return missingData\n",
    "\n",
    "def prepare_timeseries_data(input_data):\n",
    "    # calculate all the missing days data\n",
    "    missingData = find_missing_days(input_data)\n",
    "    print(missingData)\n",
    "    # Interpolate at 5 min\n",
    "    input_data = input_data.resample(\"5min\").interpolate()\n",
    "\n",
    "    # retain only day time data\n",
    "    input_data = input_data[(input_data.index.hour>6) & (input_data.index.hour<=18)]\n",
    "    # remove from the resampled data the days which were not present initially.\n",
    "    df = input_data.copy()\n",
    "    for year, missing_days in missingData.items():\n",
    "      for month, days in missing_days.items():\n",
    "          for day in days:\n",
    "              df = df[(df.index.year!=year) | (df.index.month!=month) | (df.index.day!=day)]\n",
    "    print(\"New df Len: \",len(df), \"Data Len: \",len(input_data))\n",
    "\n",
    "    # first day and last day might not contain the full day data, so remove them.\n",
    "    df = df[(df.index.month!=df.index.min().month) | (df.index.day!=df.index.min().day)]\n",
    "    df = df[(df.index.month!=df.index.max().month) | (df.index.day!=df.index.max().day)]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def replace_connectors_with_sub_values(input_data, list_of_connectors):\n",
    "  \"\"\"\n",
    "  Parameter:\n",
    "    input_data: DataFrame, from which the connetors need to be replaced with substiture vales\n",
    "    list_of_connectors: expects a list of int values in range (0, max_connectors - 1)\n",
    "\n",
    "  Returns:\n",
    "    Dataframe, with specified columns replaced with specified subustitute value\n",
    "  \"\"\"\n",
    "  for conn in list_of_connectors:\n",
    "    conn_cols = [[\"V_\"+x, \"T_\"+x, \"P_\"+x, \"R_\"+x] for x in [conn]]\n",
    "    for conn in conn_cols[0]:\n",
    "      if conn in input_data.columns:\n",
    "        input_data.loc[:,conn] = SUBSTITUE_VALUE\n",
    "      else:\n",
    "        print(conn, \" not present in input_data.\")\n",
    "  return input_data\n",
    "\n",
    "\n",
    "def drop_connectors(input_data, connectors_to_remove):\n",
    "  \"\"\"\n",
    "  This selects a connetor to be dropped from the input_data and appends the\n",
    "  new input_data to the current its data at the end\n",
    "\n",
    "  Parameter:\n",
    "    Data: DataFrame, from which the connetors need to be replaced with substiture vales\n",
    "    connectors_to_remove: A list of connectors to be removed, where each element is str(connector_number)\n",
    "  Returns:\n",
    "    Dataframe, with possible combinations of missing connector appended on the end\n",
    "  \"\"\"\n",
    "  _all_data = input_data.copy()\n",
    "  for connector_number in sorted(connectors_to_remove, reverse=True):\n",
    "    input_data = replace_connectors_with_sub_values(input_data, connector_number)\n",
    "    num_days = len(input_data.resample('1D').mean())\n",
    "    offset = pd.DateOffset(days=num_days)\n",
    "    input_data.index = input_data.index + offset\n",
    "\n",
    "    _all_data = pd.concat([_all_data, input_data], axis=0)\n",
    "\n",
    "  return _all_data\n",
    "\n",
    "def fill_substitute(input_data):\n",
    "  conn_cols = [[\"V_\"+str(x), \"T_\"+str(x), \"P_\"+str(x), \"R_\"+str(x)] for x in range(MAX_CONNECTORS)]\n",
    "  conn_to_drop = []\n",
    "  for conn in np.array(conn_cols).flatten():\n",
    "    if conn not in input_data.columns:\n",
    "      input_data.loc[:,conn] = SUBSTITUE_VALUE\n",
    "    else:\n",
    "      conn_to_drop.append(conn.split('_')[1])\n",
    "\n",
    "  _all_data = drop_connectors(input_data, set(conn_to_drop))\n",
    "\n",
    "  return _all_data\n",
    "\n",
    "def get_string_data(input_data, _s1_exoskeletons, _s2_exoskeletons):\n",
    "  vt_cols = [(\"V_\"+x, \"T_\"+x, \"P_\"+x, \"R_\"+x) for x in _s1_exoskeletons]\n",
    "  inv_cols = [\"I_dc_\", \"U_dc_\", \"P_\", \"R_\"]\n",
    "  master_cols = (['Day sin'] +\n",
    "                weather_cols +\n",
    "                [x+\"string1\" for x in inv_cols] +\n",
    "                [x for vt in vt_cols for x in vt])\n",
    "\n",
    "  string1_data = input_data[master_cols]\n",
    "  string1_data = string1_data[np.isfinite(string1_data).all(1)]\n",
    "\n",
    "  vt_cols = [(\"V_\"+x, \"T_\"+x, \"P_\"+x, \"R_\"+x) for x in _s2_exoskeletons]\n",
    "\n",
    "  master_cols = (['Day sin'] +\n",
    "                  weather_cols +\n",
    "                  [x+\"string2\" for x in inv_cols] +\n",
    "                  [x for VT in vt_cols for x in VT])\n",
    "  string2_data = input_data[master_cols]\n",
    "  string2_data = string2_data[np.isfinite(string2_data).all(1)]\n",
    "\n",
    "  new_cols = []\n",
    "  for i, x in enumerate([x for VT in vt_cols for x in VT]):\n",
    "    new_cols.append(x[:2]+str(int(i/4)))\n",
    "  new_cols = ['Day sin'] + weather_cols + [\"I_S\", \"V_S\", \"P_S\", \"R_S\"] + new_cols\n",
    "\n",
    "  string1_data.columns = new_cols\n",
    "  string2_data.columns = new_cols\n",
    "\n",
    "  return string1_data, string2_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-gxFLqcsQRwC",
    "outputId": "91129372-fa7f-4822-a803-c875c8723439"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(3, 0, replace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31w6n2pm6agK"
   },
   "source": [
    "# Get the University o Bern Data\n",
    "\n",
    "Now, we can load sensor data and get meta information about the sensors.\n",
    "\n",
    "After this is done, we need to shift the inverter data (there is a shift of 1 hour 5 mins in March data, and 5 min shift afterwards). Then data will be combined and P and R will be derived for each exoskeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S6mA2h62X21o",
    "outputId": "8aef6987-1e84-4cdf-9935-e74b676cbfe0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata file read successfully!\n",
      "Metadata file read successfully!\n",
      "Metadata file read successfully!\n"
     ]
    }
   ],
   "source": [
    "bern_data = get_sensor_data(\"./content/Bern_data_upto_16_jun.csv\")\n",
    "(s1_exoskeletons_b1,\n",
    " s2_exoskeletons_b1,\n",
    " s1_inv_sensor_b1,\n",
    " s2_inv_sensor_b1,\n",
    " s1_current_sensor_b1,\n",
    " s2_current_sensor_b1,\n",
    " metadata_b1\n",
    " ) = get_string_exoskeletons(\"./content/metadata_bfh.json\")\n",
    "\n",
    "(s1_exoskeletons_b2,\n",
    " s2_exoskeletons_b2,\n",
    " s1_inv_sensor_b2,\n",
    " s2_inv_sensor_b2,\n",
    " s1_current_sensor_b2,\n",
    " s2_current_sensor_b2,\n",
    " metadata_b2\n",
    " ) = get_string_exoskeletons(\"./content/metadata_bfh_Exp2.json\")\n",
    "\n",
    "(s1_exoskeletons_b3,\n",
    " s2_exoskeletons_b3,\n",
    " s1_inv_sensor_b3,\n",
    " s2_inv_sensor_b3,\n",
    " s1_current_sensor_b3,\n",
    " s2_current_sensor_b3,\n",
    " metadata_b3\n",
    " ) = get_string_exoskeletons(\"./content/metadata_bfh_Exp3.json\")\n",
    "\n",
    "inv_adjusted_data = append_shifted_inverter_data(bern_data,\n",
    "                                        inverter_data_path=\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "VNL0tamqS64w"
   },
   "outputs": [],
   "source": [
    "b1_end_date = '2024-04-29 00:00:00'\n",
    "b2_end_date = '2024-05-21 00:00:00'\n",
    "b3_end_date = '2024-07-17 00:00:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "vTjYQl-aMeec"
   },
   "outputs": [],
   "source": [
    "batch1_data = derive_power_resistance_features(\n",
    "                  inv_adjusted_data[inv_adjusted_data.index<b1_end_date],\n",
    "                  s1_exoskeletons_b1,\n",
    "                  s2_exoskeletons_b1,\n",
    "                  s1_current_sensor_b1,\n",
    "                  s2_current_sensor_b1)\n",
    "\n",
    "batch2_data = derive_power_resistance_features(\n",
    "                  inv_adjusted_data[(inv_adjusted_data.index > b1_end_date) &\n",
    "                                    (inv_adjusted_data.index < b2_end_date)],\n",
    "                  s1_exoskeletons_b2,\n",
    "                  s2_exoskeletons_b2,\n",
    "                  s1_current_sensor_b2,\n",
    "                  s2_current_sensor_b2)\n",
    "\n",
    "batch3_data = derive_power_resistance_features(\n",
    "                  inv_adjusted_data[(inv_adjusted_data.index > b2_end_date) &\n",
    "                                    (inv_adjusted_data.index < b3_end_date)],\n",
    "                  s1_exoskeletons_b3,\n",
    "                  s2_exoskeletons_b3,\n",
    "                  s1_current_sensor_b3,\n",
    "                  s2_current_sensor_b3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9KDP6NPD7p57"
   },
   "source": [
    "## Separate String-1 and String-2 data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YLYH3lMM8BPl"
   },
   "source": [
    "Prepare for merging String-1 and String-2 on axis-0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mOQoysHKbPz9"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "aeHE7HScF0Hr"
   },
   "outputs": [],
   "source": [
    "# This code will reduce the exoskeletons by 20%\n",
    "s1_exoskeletons_b1.remove(random.choice(s1_exoskeletons_b1))\n",
    "s1_exoskeletons_b1.remove(random.choice(s1_exoskeletons_b1))\n",
    "s2_exoskeletons_b1.remove(random.choice(s2_exoskeletons_b1))\n",
    "s2_exoskeletons_b1.remove(random.choice(s2_exoskeletons_b1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDnTnDWLbfCa"
   },
   "source": [
    "Prepare Batch1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8vTO4QL9u8Ac",
    "outputId": "4dc34878-9ebb-4839-c087-7c719b72efa2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2024: {4: [4, 14, 20, 21, 22, 23]}}\n",
      "New df Len:  6224 Data Len:  7088\n",
      "{2024: {4: [14]}}\n",
      "New df Len:  6944 Data Len:  7088\n"
     ]
    }
   ],
   "source": [
    "data1, data2 = get_string_data(batch1_data, s1_exoskeletons_b1, s2_exoskeletons_b1)\n",
    "\n",
    "data1 = prepare_timeseries_data(data1)\n",
    "data2 = prepare_timeseries_data(data2)\n",
    "\n",
    "num_days = len(data1.resample('1D').mean())\n",
    "offset = pd.DateOffset(days=num_days)\n",
    "data2.index = data2.index + offset\n",
    "\n",
    "X_batch1 = pd.concat([data1, data2], axis=0)\n",
    "\n",
    "num_of_trainable_instances_df1 = int(len(data1)/TIMESTEPS)\n",
    "num_of_trainable_instances_df2 = int(len(data2)/TIMESTEPS)\n",
    "\n",
    "\n",
    "target_batch1 = np.array([[1.0, 0., 0.]]*num_of_trainable_instances_df1 + [[0.7, 0.15, 0.15]]*num_of_trainable_instances_df2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZOXBAxwbnPP"
   },
   "source": [
    "Prepare Batch 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "oiHD1n7DjXP_"
   },
   "outputs": [],
   "source": [
    "# This code will reduce the exoskeletons by 20%\n",
    "s1_exoskeletons_b2.remove(random.choice(s1_exoskeletons_b2))\n",
    "s1_exoskeletons_b2.remove(random.choice(s1_exoskeletons_b2))\n",
    "s2_exoskeletons_b2.remove(random.choice(s2_exoskeletons_b2))\n",
    "s2_exoskeletons_b2.remove(random.choice(s2_exoskeletons_b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wnH9k23mYlbT",
    "outputId": "555ffe52-bbb1-48ce-de7a-39cbae01fe96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2024: {5: [13, 14, 16, 17, 18, 19]}}\n",
      "New df Len:  1008 Data Len:  1872\n",
      "{2024: {5: [7]}}\n",
      "New df Len:  2004 Data Len:  2148\n"
     ]
    }
   ],
   "source": [
    "data1, data2 = get_string_data(batch2_data, s1_exoskeletons_b2, s2_exoskeletons_b2)\n",
    "\n",
    "data1 = prepare_timeseries_data(data1)\n",
    "data2 = prepare_timeseries_data(data2)\n",
    "\n",
    "num_days = len(data1.resample('1D').mean())\n",
    "offset = pd.DateOffset(days=num_days)\n",
    "data2.index = data2.index + offset\n",
    "\n",
    "\n",
    "\n",
    "X_batch2 = pd.concat([data1, data2], axis=0)\n",
    "\n",
    "num_of_trainable_instances_df1 = int(len(data1)/TIMESTEPS)\n",
    "num_of_trainable_instances_df2 = int(len(data2)/TIMESTEPS)\n",
    "\n",
    "\n",
    "target_batch2 = np.array([[0.85, 0.15, 0.]]*num_of_trainable_instances_df1 + [[0.85, 0., 0.15]]*num_of_trainable_instances_df2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1O7_cUAqbsmL"
   },
   "source": [
    "Prepare Batch 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "dnlna_fajdB6"
   },
   "outputs": [],
   "source": [
    "# This code will reduce the exoskeletons by 20%\n",
    "s1_exoskeletons_b3.remove(random.choice(s1_exoskeletons_b3))\n",
    "s1_exoskeletons_b3.remove(random.choice(s1_exoskeletons_b3))\n",
    "s2_exoskeletons_b3.remove(random.choice(s2_exoskeletons_b3))\n",
    "s2_exoskeletons_b3.remove(random.choice(s2_exoskeletons_b3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jHQr2bnFZJVj",
    "outputId": "8e0653c0-a396-4561-c817-b9139c9d6b42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2024: {5: []}}\n",
      "New df Len:  528 Data Len:  528\n",
      "{2024: {6: []}}\n",
      "New df Len:  3888 Data Len:  3888\n"
     ]
    }
   ],
   "source": [
    "data1, data2 = get_string_data(batch3_data, s1_exoskeletons_b3, s2_exoskeletons_b3)\n",
    "\n",
    "data1 = prepare_timeseries_data(data1)\n",
    "data2 = prepare_timeseries_data(data2)\n",
    "\n",
    "num_days = len(data1.resample('1D').mean())\n",
    "offset = pd.DateOffset(days=num_days)\n",
    "data2.index = data2.index + offset\n",
    "\n",
    "\n",
    "\n",
    "X_batch3 = pd.concat([data1, data2], axis=0)\n",
    "\n",
    "num_of_trainable_instances_df1 = int(len(data1)/TIMESTEPS)\n",
    "num_of_trainable_instances_df2 = int(len(data2)/TIMESTEPS)\n",
    "\n",
    "\n",
    "target_batch3 = np.array([[0.85, 0.09, 0.06]]*num_of_trainable_instances_df1 + [[0.85, 0.06, 0.09]]*num_of_trainable_instances_df2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sPDu4hQxKXpD",
    "outputId": "af36d5ec-49a1-4d55-d2ec-930ca0e41428"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.85, 0.09, 0.06]), array([0.85, 0.06, 0.09]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round([28/33,3/33,  2/33],2), np.round([28/33,2/33,  3/33],2),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "By51qPgwnCrI"
   },
   "source": [
    "#Get the New Delhi Testsite Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "l2ddVkl0Ll2V"
   },
   "outputs": [],
   "source": [
    "len_wrt_timestep = lambda df: int(len(df)/TIMESTEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "y6BgyTQHninM",
    "outputId": "266e9a35-057c-4677-8a09-5b590d1b673b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2022: {12: [2, 3, 6, 7, 11, 12, 13, 14]}}\n",
      "New df Len:  12846 Data Len:  13998\n",
      "{2022: {12: [23, 30]}, 2023: {12: []}}\n",
      "New df Len:  5333 Data Len:  5621\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day sin</th>\n",
       "      <th>G_0</th>\n",
       "      <th>I_S</th>\n",
       "      <th>V_S</th>\n",
       "      <th>P_S</th>\n",
       "      <th>R_S</th>\n",
       "      <th>V_0</th>\n",
       "      <th>T_0</th>\n",
       "      <th>P_0</th>\n",
       "      <th>R_0</th>\n",
       "      <th>V_1</th>\n",
       "      <th>T_1</th>\n",
       "      <th>P_1</th>\n",
       "      <th>R_1</th>\n",
       "      <th>V_2</th>\n",
       "      <th>T_2</th>\n",
       "      <th>P_2</th>\n",
       "      <th>R_2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-09-10 07:00:00</th>\n",
       "      <td>0.566813</td>\n",
       "      <td>313.909216</td>\n",
       "      <td>4.010784</td>\n",
       "      <td>184.835294</td>\n",
       "      <td>741.725490</td>\n",
       "      <td>46.087632</td>\n",
       "      <td>3.0</td>\n",
       "      <td>36.431373</td>\n",
       "      <td>12.591324</td>\n",
       "      <td>0.715141</td>\n",
       "      <td>3.0</td>\n",
       "      <td>37.539216</td>\n",
       "      <td>12.556765</td>\n",
       "      <td>0.717149</td>\n",
       "      <td>3.053922</td>\n",
       "      <td>34.539216</td>\n",
       "      <td>12.407328</td>\n",
       "      <td>0.751576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-10 07:05:00</th>\n",
       "      <td>0.574561</td>\n",
       "      <td>314.038456</td>\n",
       "      <td>4.010294</td>\n",
       "      <td>184.838235</td>\n",
       "      <td>741.647059</td>\n",
       "      <td>46.093876</td>\n",
       "      <td>3.0</td>\n",
       "      <td>36.411765</td>\n",
       "      <td>12.588309</td>\n",
       "      <td>0.715297</td>\n",
       "      <td>3.0</td>\n",
       "      <td>37.514706</td>\n",
       "      <td>12.551912</td>\n",
       "      <td>0.717410</td>\n",
       "      <td>3.051471</td>\n",
       "      <td>34.514706</td>\n",
       "      <td>12.392904</td>\n",
       "      <td>0.751251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-10 07:10:00</th>\n",
       "      <td>0.582310</td>\n",
       "      <td>314.167696</td>\n",
       "      <td>4.009804</td>\n",
       "      <td>184.841176</td>\n",
       "      <td>741.568627</td>\n",
       "      <td>46.100120</td>\n",
       "      <td>3.0</td>\n",
       "      <td>36.392157</td>\n",
       "      <td>12.585294</td>\n",
       "      <td>0.715452</td>\n",
       "      <td>3.0</td>\n",
       "      <td>37.490196</td>\n",
       "      <td>12.547059</td>\n",
       "      <td>0.717671</td>\n",
       "      <td>3.049020</td>\n",
       "      <td>34.490196</td>\n",
       "      <td>12.378480</td>\n",
       "      <td>0.750926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-10 07:15:00</th>\n",
       "      <td>0.590058</td>\n",
       "      <td>314.296936</td>\n",
       "      <td>4.009314</td>\n",
       "      <td>184.844118</td>\n",
       "      <td>741.490196</td>\n",
       "      <td>46.106364</td>\n",
       "      <td>3.0</td>\n",
       "      <td>36.372549</td>\n",
       "      <td>12.582279</td>\n",
       "      <td>0.715608</td>\n",
       "      <td>3.0</td>\n",
       "      <td>37.465686</td>\n",
       "      <td>12.542206</td>\n",
       "      <td>0.717932</td>\n",
       "      <td>3.046569</td>\n",
       "      <td>34.465686</td>\n",
       "      <td>12.364056</td>\n",
       "      <td>0.750600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-10 07:20:00</th>\n",
       "      <td>0.597807</td>\n",
       "      <td>314.426176</td>\n",
       "      <td>4.008824</td>\n",
       "      <td>184.847059</td>\n",
       "      <td>741.411765</td>\n",
       "      <td>46.112608</td>\n",
       "      <td>3.0</td>\n",
       "      <td>36.352941</td>\n",
       "      <td>12.579265</td>\n",
       "      <td>0.715763</td>\n",
       "      <td>3.0</td>\n",
       "      <td>37.441176</td>\n",
       "      <td>12.537353</td>\n",
       "      <td>0.718193</td>\n",
       "      <td>3.044118</td>\n",
       "      <td>34.441176</td>\n",
       "      <td>12.349632</td>\n",
       "      <td>0.750275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Day sin         G_0       I_S         V_S         P_S  \\\n",
       "Time                                                                          \n",
       "2022-09-10 07:00:00  0.566813  313.909216  4.010784  184.835294  741.725490   \n",
       "2022-09-10 07:05:00  0.574561  314.038456  4.010294  184.838235  741.647059   \n",
       "2022-09-10 07:10:00  0.582310  314.167696  4.009804  184.841176  741.568627   \n",
       "2022-09-10 07:15:00  0.590058  314.296936  4.009314  184.844118  741.490196   \n",
       "2022-09-10 07:20:00  0.597807  314.426176  4.008824  184.847059  741.411765   \n",
       "\n",
       "                           R_S  V_0        T_0        P_0       R_0  V_1  \\\n",
       "Time                                                                       \n",
       "2022-09-10 07:00:00  46.087632  3.0  36.431373  12.591324  0.715141  3.0   \n",
       "2022-09-10 07:05:00  46.093876  3.0  36.411765  12.588309  0.715297  3.0   \n",
       "2022-09-10 07:10:00  46.100120  3.0  36.392157  12.585294  0.715452  3.0   \n",
       "2022-09-10 07:15:00  46.106364  3.0  36.372549  12.582279  0.715608  3.0   \n",
       "2022-09-10 07:20:00  46.112608  3.0  36.352941  12.579265  0.715763  3.0   \n",
       "\n",
       "                           T_1        P_1       R_1       V_2        T_2  \\\n",
       "Time                                                                       \n",
       "2022-09-10 07:00:00  37.539216  12.556765  0.717149  3.053922  34.539216   \n",
       "2022-09-10 07:05:00  37.514706  12.551912  0.717410  3.051471  34.514706   \n",
       "2022-09-10 07:10:00  37.490196  12.547059  0.717671  3.049020  34.490196   \n",
       "2022-09-10 07:15:00  37.465686  12.542206  0.717932  3.046569  34.465686   \n",
       "2022-09-10 07:20:00  37.441176  12.537353  0.718193  3.044118  34.441176   \n",
       "\n",
       "                           P_2       R_2  \n",
       "Time                                      \n",
       "2022-09-10 07:00:00  12.407328  0.751576  \n",
       "2022-09-10 07:05:00  12.392904  0.751251  \n",
       "2022-09-10 07:10:00  12.378480  0.750926  \n",
       "2022-09-10 07:15:00  12.364056  0.750600  \n",
       "2022-09-10 07:20:00  12.349632  0.750275  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = get_sensor_data(\"./content/pureStr1_Batch3_2022_TSDel.csv\", index_column='Time')\n",
    "s1.loc[:,'C_P'] = s1['C_I']*s1['C_V']\n",
    "s1.loc[:,'C_P_C2'] = s1['C_I_C2']*s1['C_V_C2']\n",
    "s1.loc[:,'C_P_C3'] = s1['C_I_C3']*s1['C_V_C3']\n",
    "doi_s1_testsite = s1[['Day sin', 'W_G', 'S1_C', 'S1_V', 'S1_P', 'S1_R',\n",
    "                      'C_V', 'C_Tsur',  'C_P', 'C_R',\n",
    "                      'C_V_C2', 'C_Tsur_C2', 'C_P_C2',  'C_R_C2',\n",
    "                      'C_V_C3', 'C_Tsur_C3', 'C_P_C3', 'C_R_C3']]\n",
    "doi_s1_testsite.columns = ['Day sin', 'G_0', 'I_S', 'V_S', 'P_S', 'R_S',\n",
    "                           'V_0', 'T_0',  'P_0', 'R_0',\n",
    "                           'V_1', 'T_1',  'P_1', 'R_1',\n",
    "                           'V_2', 'T_2',  'P_2', 'R_2', ]\n",
    "\n",
    "num_days = len(doi_s1_testsite.resample(\"1D\").mean())\n",
    "offset = pd.DateOffset(days=num_days)\n",
    "\n",
    "s2 = get_sensor_data(\"./content/pureStr2_Batch3_2022_TSDel.csv\", index_column='Time')\n",
    "s2.loc[:,'C_P'] = s2['C_I']*s2['C_V']\n",
    "s2.loc[:,'C_P_C2'] = s2['C_I_C2']*s2['C_V_C2']\n",
    "s2.loc[:,'C_P_C3'] = s2['C_I_C3']*s2['C_V_C3']\n",
    "doi_s2_testsite = s2[['Day sin', 'W_G', 'S2_C', 'S2_V', 'S2_P', 'S2_R',\n",
    "                      'C_V', 'C_Tsur',  'C_P', 'C_R',\n",
    "                      'C_V_C2', 'C_Tsur_C2', 'C_P_C2',  'C_R_C2',\n",
    "                      'C_V_C3', 'C_Tsur_C3', 'C_P_C3', 'C_R_C3']]\n",
    "doi_s2_testsite.columns = ['Day sin', 'G_0', 'I_S', 'V_S', 'P_S', 'R_S',\n",
    "                           'V_0', 'T_0',  'P_0', 'R_0',\n",
    "                           'V_1', 'T_1',  'P_1', 'R_1',\n",
    "                           'V_2', 'T_2',  'P_2', 'R_2', ]\n",
    "\n",
    "\n",
    "doi_s2_testsite.index += offset\n",
    "\n",
    "doi_s1_testsite = doi_s1_testsite[doi_s1_testsite['R_S']!=inf]\n",
    "doi_s1_testsite = prepare_timeseries_data(doi_s1_testsite)\n",
    "doi_s2_testsite = doi_s2_testsite[doi_s2_testsite['R_S']!=inf]\n",
    "doi_s2_testsite = prepare_timeseries_data(doi_s2_testsite)\n",
    "\n",
    "X_testsite = pd.concat([doi_s1_testsite, doi_s2_testsite], axis=0)\n",
    "\n",
    "s1_y_testsite_len_wrt_timesteps = len_wrt_timestep(doi_s1_testsite)\n",
    "s2_y_testsite_len_wrt_timesteps = len_wrt_timestep(doi_s2_testsite)\n",
    "\n",
    "testsite_y = np.array([[0.50, 0., 0.50]]*s1_y_testsite_len_wrt_timesteps+[[0.165, 0.335, 0.50]]*s2_y_testsite_len_wrt_timesteps)\n",
    "\n",
    "X_testsite.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iAX6YZ7e8UdO"
   },
   "source": [
    "# Create and Train the time series model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JLHrh3NeZEIC"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MnsWU6ulymaU",
    "outputId": "1789b223-ac89-48df-c242-159d49549a5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - loss: 0.1165\n",
      "Epoch 2/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0135\n",
      "Epoch 3/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0119\n",
      "Epoch 4/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0136\n",
      "Epoch 5/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0124\n",
      "Epoch 6/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0104\n",
      "Epoch 7/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0088\n",
      "Epoch 8/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0100\n",
      "Epoch 9/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0110\n",
      "Epoch 10/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0095\n",
      "Epoch 11/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0097\n",
      "Epoch 12/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0092\n",
      "Epoch 13/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0089\n",
      "Epoch 14/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0080\n",
      "Epoch 15/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0077\n",
      "Epoch 16/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0082\n",
      "Epoch 17/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0077\n",
      "Epoch 18/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0088\n",
      "Epoch 19/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0081\n",
      "Epoch 20/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0071\n",
      "Epoch 21/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0079\n",
      "Epoch 22/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0080\n",
      "Epoch 23/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0072\n",
      "Epoch 24/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0083\n",
      "Epoch 25/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0070\n",
      "Epoch 26/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0055\n",
      "Epoch 27/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0078\n",
      "Epoch 28/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0078\n",
      "Epoch 29/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0080\n",
      "Epoch 30/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0060\n",
      "Epoch 31/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0064\n",
      "Epoch 32/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0072\n",
      "Epoch 33/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0075\n",
      "Epoch 34/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0053\n",
      "Epoch 35/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0058\n",
      "Epoch 36/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0064\n",
      "Epoch 37/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0064\n",
      "Epoch 38/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0074\n",
      "Epoch 39/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0060\n",
      "Epoch 40/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0050\n",
      "Epoch 41/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0070\n",
      "Epoch 42/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0060\n",
      "Epoch 43/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0060\n",
      "Epoch 44/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0058\n",
      "Epoch 45/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0060\n",
      "Epoch 46/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0046\n",
      "Epoch 47/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0060\n",
      "Epoch 48/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0048\n",
      "Epoch 49/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0050\n",
      "Epoch 50/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0049\n",
      "Epoch 51/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0053\n",
      "Epoch 52/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0049\n",
      "Epoch 53/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0057\n",
      "Epoch 54/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0066\n",
      "Epoch 55/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0052\n",
      "Epoch 56/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0058\n",
      "Epoch 57/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0054\n",
      "Epoch 58/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0061\n",
      "Epoch 59/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0058\n",
      "Epoch 60/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0051\n",
      "Epoch 61/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0054\n",
      "Epoch 62/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0055\n",
      "Epoch 63/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0058\n",
      "Epoch 64/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0040\n",
      "Epoch 65/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0056\n",
      "Epoch 66/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0044\n",
      "Epoch 67/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0041\n",
      "Epoch 68/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0058\n",
      "Epoch 69/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0062\n",
      "Epoch 70/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0055\n",
      "Epoch 71/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0051\n",
      "Epoch 72/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0045\n",
      "Epoch 73/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0050\n",
      "Epoch 74/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0045\n",
      "Epoch 75/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0046\n",
      "Epoch 76/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0039\n",
      "Epoch 77/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0041\n",
      "Epoch 78/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0041\n",
      "Epoch 79/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0041\n",
      "Epoch 80/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0068\n",
      "Epoch 81/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0061\n",
      "Epoch 82/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0059\n",
      "Epoch 83/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0058\n",
      "Epoch 84/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0053\n",
      "Epoch 85/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0042\n",
      "Epoch 86/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0053\n",
      "Epoch 87/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0058\n",
      "Epoch 88/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 0.0040\n",
      "Epoch 89/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0034\n",
      "Epoch 90/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0037\n",
      "Epoch 91/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0036\n",
      "Epoch 92/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0045\n",
      "Epoch 93/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 0.0041\n",
      "Epoch 94/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0046\n",
      "Epoch 95/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0044\n",
      "Epoch 96/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0054\n",
      "Epoch 97/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0040\n",
      "Epoch 98/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0055\n",
      "Epoch 99/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0033\n",
      "Epoch 100/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0035\n",
      "Epoch 101/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0029\n",
      "Epoch 102/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0031\n",
      "Epoch 103/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0031\n",
      "Epoch 104/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0038\n",
      "Epoch 105/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0041\n",
      "Epoch 106/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0030\n",
      "Epoch 107/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0041\n",
      "Epoch 108/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0027\n",
      "Epoch 109/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0039\n",
      "Epoch 110/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0029\n",
      "Epoch 111/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0035\n",
      "Epoch 112/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0026\n",
      "Epoch 113/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0027\n",
      "Epoch 114/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0031\n",
      "Epoch 115/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0035\n",
      "Epoch 116/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0024\n",
      "Epoch 117/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0024\n",
      "Epoch 118/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0034\n",
      "Epoch 119/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0054\n",
      "Epoch 120/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0048\n",
      "Epoch 121/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0039\n",
      "Epoch 122/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0040\n",
      "Epoch 123/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.0037\n",
      "Epoch 124/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0025\n",
      "Epoch 125/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0024\n",
      "Epoch 126/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0026\n",
      "Epoch 127/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0034\n",
      "Epoch 128/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0026\n",
      "Epoch 129/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0034\n",
      "Epoch 130/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0029\n",
      "Epoch 131/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0043\n",
      "Epoch 132/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0067\n",
      "Epoch 133/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0055\n",
      "Epoch 134/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0046\n",
      "Epoch 135/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0037\n",
      "Epoch 136/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0033\n",
      "Epoch 137/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0031\n",
      "Epoch 138/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0025\n",
      "Epoch 139/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0026\n",
      "Epoch 140/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0019\n",
      "Epoch 141/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0022\n",
      "Epoch 142/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.0025\n",
      "Epoch 143/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0034\n",
      "Epoch 144/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0021\n",
      "Epoch 145/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0022\n",
      "Epoch 146/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0015\n",
      "Epoch 147/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0019\n",
      "Epoch 148/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0014\n",
      "Epoch 149/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0016\n",
      "Epoch 150/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0024\n",
      "Epoch 151/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0017\n",
      "Epoch 152/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0020\n",
      "Epoch 153/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0029\n",
      "Epoch 154/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 0.0013 \n",
      "Epoch 155/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0030\n",
      "Epoch 156/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0016\n",
      "Epoch 157/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0016\n",
      "Epoch 158/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 0.0016\n",
      "Epoch 159/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - loss: 0.0024\n",
      "Epoch 160/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 0.0012  \n",
      "Epoch 161/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0013\n",
      "Epoch 162/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 9.1034e-04\n",
      "Epoch 163/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0012\n",
      "Epoch 164/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 0.0011\n",
      "Epoch 165/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 7.5369e-04\n",
      "Epoch 166/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0020\n",
      "Epoch 167/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.0016\n",
      "Epoch 168/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 7.9011e-04\n",
      "Epoch 169/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 6.9571e-04\n",
      "Epoch 170/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 6.6731e-04\n",
      "Epoch 171/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 6.5266e-04\n",
      "Epoch 172/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 5.0380e-04\n",
      "Epoch 173/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 6.7461e-04\n",
      "Epoch 174/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 8.9372e-04\n",
      "Epoch 175/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 6.5314e-04\n",
      "Epoch 176/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 6.3267e-04\n",
      "Epoch 177/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 8.7871e-04\n",
      "Epoch 178/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 9.2886e-04\n",
      "Epoch 179/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 6.6535e-04\n",
      "Epoch 180/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 9.0851e-04\n",
      "Epoch 181/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0012    \n",
      "Epoch 182/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 9.7151e-04\n",
      "Epoch 183/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 6.7486e-04\n",
      "Epoch 184/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 7.5052e-04\n",
      "Epoch 185/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0019\n",
      "Epoch 186/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 0.0016  \n",
      "Epoch 187/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0016\n",
      "Epoch 188/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0011    \n",
      "Epoch 189/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0011  \n",
      "Epoch 190/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0011    \n",
      "Epoch 191/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - loss: 0.0013\n",
      "Epoch 192/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0015\n",
      "Epoch 193/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 9.8460e-04\n",
      "Epoch 194/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 5.5007e-04\n",
      "Epoch 195/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - loss: 6.1004e-04\n",
      "Epoch 196/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 5.7336e-04\n",
      "Epoch 197/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 0.0019\n",
      "Epoch 198/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0015\n",
      "Epoch 199/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0010    \n",
      "Epoch 200/200\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - loss: 7.0985e-04\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 517ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.0506958 , 0.00552976, 0.05622558])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset_X = pd.concat([X_batch1, X_batch2], axis=0)\n",
    "final_dataset_y = np.concatenate((target_batch1, target_batch2), axis=0)\n",
    "\n",
    "#final_dataset_X = X_testsite.copy()\n",
    "#final_dataset_y = np.array(testsite_y)\n",
    "\n",
    "num_of_trainable_instances = int(len(final_dataset_X)/TIMESTEPS)\n",
    "features = len(final_dataset_X.columns)\n",
    "scaler = StandardScaler()\n",
    "data_scaled = (np.array(final_dataset_X)).reshape(num_of_trainable_instances, TIMESTEPS, features)\n",
    "\n",
    "ai_model = timeseries_ml_model(time_steps= TIMESTEPS, input_features=features, epochs=200)\n",
    "ai_model.get_data(data_scaled, final_dataset_y, test_split=1)\n",
    "\n",
    "ai_model.make_dl_model()\n",
    "ai_model.train_dl_model()\n",
    "\n",
    "ypred, yact = ai_model.make_predictions(model=\"dl\")\n",
    "\n",
    "calucluate_mean_absolute_error(ypred, yact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cl7RPSDD7FUN"
   },
   "source": [
    "# Testing Bern Batch-3 Data\n",
    "we will load the data of batch-3 from Bern. Here the String Configuration is as follows:\n",
    "\n",
    "\n",
    "1.   String-1\n",
    "\n",
    "*   5 Normal\n",
    "*   3 Bad Crimp\n",
    "*   2 Crossmated\n",
    "\n",
    "\n",
    "2.   String-2\n",
    "*   5 Normal\n",
    "*   2 Bad Crimp\n",
    "*   3 Crossmated\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0HBnSTi5KAJp",
    "outputId": "379f6295-6bf6-45d4-9ad8-271a60fba7f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 586ms/step\n",
      "Test Data Shape: (27, 144, 38)\n",
      "Mean absolute Error in predicting S1 Composition: [0.08227112 0.05571569 0.04213214]\n",
      "Average Error: 0.06003965183034723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.927338  , 0.0069156 , 0.06574637], dtype=float32),\n",
       " array([0.9858021 , 0.00139313, 0.01280471], dtype=float32))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = (np.array(X_batch3)).reshape(int(len(X_batch3)/TIMESTEPS), TIMESTEPS, features)\n",
    "\n",
    "ypred = ai_model.dl_model.predict(test_data)\n",
    "print(f\"Test Data Shape: {test_data.shape}\")\n",
    "print(f\"Mean absolute Error in predicting S1 Composition: {calucluate_mean_absolute_error(ypred, target_batch3)}\\nAverage Error: {calucluate_mean_absolute_error(ypred, target_batch3).mean()}\")\n",
    "c1=[]\n",
    "c2=[]\n",
    "for i,j in zip(ypred, target_batch3):\n",
    "  if (j==[0.85, 0.06, 0.09]).all():\n",
    "    c1.append(i)\n",
    "  elif (j==[0.85, 0.09, 0.06]).all():\n",
    "    c2.append(i)\n",
    "\n",
    "np.mean(c1, axis=0), np.mean(c2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tofmeAGlbVAr",
    "outputId": "df87afd3-51f2-4e4c-cebb-f7b975e9d8a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.9198564 , 0.07085668, 0.00928688], dtype=float32),\n",
       " array([0.88428384, 0.01427967, 0.10143644], dtype=float32),\n",
       " array([0.91489685, 0.04568846, 0.03941475], dtype=float32),\n",
       " array([0.7931185 , 0.11184084, 0.09504069], dtype=float32),\n",
       " array([0.9858021 , 0.00139313, 0.01280471], dtype=float32),\n",
       " array([0.927338  , 0.0069156 , 0.06574637], dtype=float32))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_X = pd.concat([X_batch1, X_batch2, X_batch3], axis=0)\n",
    "dataset_y = np.concatenate((target_batch1, target_batch2, target_batch3), axis=0)\n",
    "\n",
    "num_of_trainable_instances = int(len(dataset_X)/TIMESTEPS)\n",
    "features = len(dataset_X.columns)\n",
    "\n",
    "test_data = (np.array(dataset_X)).reshape(num_of_trainable_instances, TIMESTEPS, features)\n",
    "pred = ai_model.dl_model.predict(test_data)\n",
    "c1=[]\n",
    "c2=[]\n",
    "c3=[]\n",
    "c4=[]\n",
    "c5=[]\n",
    "c6=[]\n",
    "for i,j in zip(pred, dataset_y):\n",
    "  if (j==[0.85  , 0.15, 0.]).all():\n",
    "    c1.append(i)\n",
    "  elif (j==[0.85, 0.  , 0.15]).all():\n",
    "    c2.append(i)\n",
    "  elif (j==[1, 0, 0.]).all():\n",
    "    c3.append(i)\n",
    "  elif (j==[0.7, 0.15, 0.15]).all():\n",
    "    c4.append(i)\n",
    "  elif (j==[0.85, 0.09, 0.06]).all():\n",
    "    c5.append(i)\n",
    "  elif (j==[0.85, 0.06, 0.09]).all():\n",
    "    c6.append(i)\n",
    "\n",
    "np.mean(c1, axis=0), np.mean(c2, axis=0), np.mean(c3, axis=0), np.mean(c4, axis=0), np.mean(c5, axis=0), np.mean(c6, axis=0)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "ovVPvLSQwd4K",
    "PftYx7i7mLVk",
    "8ruggjk3wkry",
    "M4zRDerSUW7A",
    "By51qPgwnCrI"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
